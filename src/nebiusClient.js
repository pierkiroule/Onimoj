// src/nebiusClient.js
// ‚ö° Client universel Nebius Studio Chat (complet + streaming)

const API_URL =
  import.meta.env.VITE_NEBIUS_API_URL ||
  "https://api.studio.nebius.com/v1/chat/completions"
// Support both the correct name and the older one to avoid prod breakage
const API_KEY =
  import.meta.env.VITE_NEBIUS_API_KEY || import.meta.env.VITE_NEBIUS_KEY

/**
 * Fonction principale : demande √† Nebius une r√©ponse textuelle.
 * @param {string} prompt - message utilisateur
 * @param {object} options :
 *    - model : mod√®le Nebius (d√©faut : google/gemma-2-2b-it)
 *    - systemPrompt : instructions syst√®me
 *    - temperature : cr√©ativit√©
 *    - stream : true ‚Üí active l‚Äôaffichage progressif
 *    - onToken : callback(token) ‚Üí re√ßoit chaque fragment
 * @returns {Promise<string>} - texte complet g√©n√©r√©
 */
export async function askNebius(prompt, options = {}) {
  const body = {
    model: options.model || "google/gemma-2-2b-it",
    messages: [
      {
        role: "system",
        content:
          options.systemPrompt ||
          "Tu es un assistant po√©tique et bienveillant. R√©ponds en fran√ßais, avec des images sensorielles, un ton apaisant et concis.",
      },
      {
        role: "user",
        content: [{ type: "text", text: prompt }],
      },
    ],
    temperature: options.temperature ?? 0.8,
    stream: options.stream ?? false,
  }

  try {
    if (!API_KEY) {
      console.error(
        "‚õî Cl√© API Nebius absente. D√©finis VITE_NEBIUS_API_KEY dans tes variables d'environnement (et red√©ploie)."
      )
      return ""
    }
    const res = await fetch(API_URL, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${API_KEY}`,
        "Content-Type": "application/json",
        ...(options.stream ? { Accept: "text/event-stream" } : {}),
      },
      body: JSON.stringify(body),
    })

    // üö® Si erreur HTTP
    if (!res.ok) {
      const errText = await res.text()
      console.error("‚ùå Erreur Nebius:", errText)
      return ""
    }

    // ‚ö° Mode streaming : lecture progressive du flux texte
    if (options.stream) {
      const reader = res.body.getReader()
      const decoder = new TextDecoder("utf-8")
      let fullText = ""
      while (true) {
        const { done, value } = await reader.read()
        if (done) break
        const chunk = decoder.decode(value)
        const tokens = extractTokens(chunk)
        for (const token of tokens) {
          fullText += token
          options.onToken?.(token) // callback √† chaque fragment
        }
      }
      return fullText.trim()
    }

    // üåä R√©ponse compl√®te (non-stream√©e)
    const data = await res.json()
    return (
      data.choices?.[0]?.message?.content?.[0]?.text?.trim() ||
      data.choices?.[0]?.message?.content?.trim() ||
      ""
    )
  } catch (err) {
    console.error("‚ö†Ô∏è Erreur connexion Nebius:", err)
    return ""
  }
}

/**
 * Fonction utilitaire pour extraire les tokens texte depuis le flux SSE
 * @param {string} chunk - bloc brut de donn√©es
 * @returns {string[]} - liste de tokens
 */
function extractTokens(chunk) {
  const tokens = []
  const lines = chunk.split("\n").filter((l) => l.startsWith("data:"))
  for (const line of lines) {
    try {
      const json = JSON.parse(line.replace("data:", "").trim())
      const text = json?.choices?.[0]?.delta?.content?.[0]?.text
      if (text) tokens.push(text)
    } catch {
      /* ignore parsing errors */
    }
  }
  return tokens
}